{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Sampling Data in Python\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Basic Sampling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Take 10 rows as sample\n",
    "pts_vs_flavor_samp = pts_vs_flavor_pop.sample(n=10)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sampling Bias\n",
    "Convenience sampling—collecting data using the easiest method—can result in samples that aren't representative of the population.\n",
    "Visualizing the distributions of the population and the sample can help determine whether or not the sample is representative of the population.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize the hist of the whole dataset and a sample of the dataset\n",
    "coffee_ratings_first10[\"total_cup_points\"].hist(bins=np.arange(59,93, 2)) #! arange will stop at 91"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pseudo-random number generation\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate random numbers from a Uniform(-3, 3)\n",
    "uniforms = np.random.uniform(low=-3, high=3, size=5000)\n",
    "\n",
    "# Generate random numbers from a Normal(5, 2)\n",
    "normals = np.random.normal(loc=5,scale=2, size=5000)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sampling Method"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# simple random sampling\n",
    "# Sample 70 rows using simple random sampling and set the seed\n",
    "attrition_samp = attrition_pop.sample(n=70,random_state=18900217)\n",
    "\n",
    "# Systematic sampling\n",
    "# Systematic sampling - defining the interval\n",
    "sample_size = 5\n",
    "pop_size = len(coffee_ratings)\n",
    "interval = pop_size//sample_size\n",
    "# Select rows\n",
    "coffee_ratings.ilocl[::interval]\n",
    "#! Systematic sampling is only safe if we don't see a pattern in the dataset scatter plot\n",
    "## Add an index column\n",
    "coffee_ratings_with_id = coffee_ratings.reset_index()\n",
    "coffee_ratings_with_id.plot(x=\"index\", y=\"aftertaste\", kind=\"scatter\")plt.show()\n",
    "# How to make systematic sampling safe?\n",
    "#* Shuffling rows + systematic sampling is the same as simple random sampling\n",
    "shuffled =coffee_ratings.sample(frac=1)\n",
    "shuffled =shuffled.reset_index(drop=True).reset_index()\n",
    "shuffled.plot(x=\"index\",y=\"aftertaste\", kind=\"scatter\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Stratified and weighted random sampling\n",
    "**Stratified sampling**\n",
    "Split the population into subgroups\n",
    "Use simple random sampling on every subgroup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Proportional stratified sampling\n",
    "# Proportion of employees by Education level\n",
    "education_counts_pop = attrition_pop['Education'].value_counts(normalize=True)\n",
    "\n",
    "# Proportional stratified sampling for 40% of each Education group\n",
    "attrition_strat = attrition_pop.groupby('Education').sample(frac=0.4, random_state=2022)\n",
    "\n",
    "# Print the sample\n",
    "print(attrition_strat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Equal counts stratified sampling\n",
    "# Get 30 employees from each Education group\n",
    "attrition_eq = attrition_pop.groupby('Education')\\\n",
    "\t.sample(n=30, random_state=2022)      \n",
    "\n",
    "# Get the proportions from attrition_eq\n",
    "education_counts_eq = attrition_eq['Education'].value_counts(normalize=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Weighted random sampling\n",
    "#* Specify weights to adjust the relative probability of a row being sampled\n",
    "# Sample 400 employees weighted by YearsAtCompany\n",
    "attrition_weight = attrition_pop.sample(n=400, weights=\"YearsAtCompany\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Cluster sampling**\n",
    "Use simple random sampling to pick some subgroups\n",
    "Use simple random sampling on only those subgroups"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a list of unique JobRole values\n",
    "job_roles_pop = list(attrition_pop['JobRole'].unique())\n",
    "# Randomly sample four JobRole values\n",
    "job_roles_samp = random.sample(job_roles_pop, k=4)\n",
    "# Filter for rows where JobRole is in job_roles_samp\n",
    "jobrole_condition = attrition_pop['JobRole'].isin(job_roles_samp)\n",
    "attrition_filtered = attrition_pop[jobrole_condition]\n",
    "# Remove categories with no rows\n",
    "attrition_filtered['JobRole'] = attrition_filtered['JobRole'].cat.remove_unused_categories()\n",
    "\n",
    "# Randomly sample 10 employees from each sampled job role\n",
    "attrition_clust = attrition_filtered.groupby('JobRole').sample(n=10,random_state=2022)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sampling Distributions\n",
    "quantify the accuracy of sample statistics using relative errors, and measure variation in estimates by generating sampling distributions\n",
    "### Relative Error in point estimates\n",
    "The size of the sample take affects how accurately the point estimates reflect the corresponding population parameter. For example, when calculate a sample mean, if want it to be close to the population mean. However, if sample is too small, this might not be the case.\n",
    "\n",
    "The most common metric for assessing accuracy is \"relative error\". This is the absolute difference between the population parameter and the point estimate, all divided by the population parameter. It is sometimes expressed as a percentage."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Relative Error in point estimates\n",
    "# Calculate the relative error percentage\n",
    "rel_error_pct50 = 100*abs(mean_attrition_srs50-mean_attrition_pop)/mean_attrition_pop"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### sampling distribution\n",
    "A sampling distribution is a distribution ofreplicates of point estimates.\n",
    "\n",
    "As sample size increases, on average each sample mean has a lower relative error compared to the population mean, thus reducing the range of the distribution."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Generate 1000 means\n",
    "mean_cup_points_1000 = []\n",
    "for i in range(1000):\n",
    "    mean_cup_points_1000.append(\n",
    "        coffee_ratings.sample(n=30)['total_cup_points'].mean()\n",
    "        )\n",
    "print(mean_cup_points_1000)\n",
    "# Plot the distibution of sample mean\n",
    "import matplotlib.pyplot as plt\n",
    "plt.hist(mean_cup_points_1000,bins=30)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Approximate sampling distributions\n",
    "The exact sampling distribution can only be calculated if you know what the population is and if the problems are small and simple enough to compute. Otherwise, the approximate sampling distribution must be used."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Expand a grid representing 5 8-sided dice\n",
    "dice = expand_grid(\n",
    "  {'die1': [1, 2, 3, 4, 5, 6, 7, 8],\n",
    "   'die2': [1, 2, 3, 4, 5, 6, 7, 8],\n",
    "   'die3': [1, 2, 3, 4, 5, 6, 7, 8],\n",
    "   'die4': [1, 2, 3, 4, 5, 6, 7, 8],\n",
    "   'die5': [1, 2, 3, 4, 5, 6, 7, 8]\n",
    "  })\n",
    "\n",
    "# Add a column of mean rolls and convert to a categorical\n",
    "dice['mean_roll'] = (dice['die1']+dice['die2']+dice['die3']+dice['die4']+dice['die5']+dice['die6']+dice['die7']+dice['die8'])/4               \n",
    "dice['mean_roll'] = dice['mean_roll'].astype('category')\n",
    "\n",
    "# Print result\n",
    "print(dice)\n",
    "# Draw a bar plot of mean_roll\n",
    "dice['mean_roll'].value_counts(sort=False).plot(kind='bar')\n",
    "plt.show()\n",
    "\n",
    "# Sample one to eight, five times, with replacement\n",
    "five_rolls = np.random.choice(list(range(1, 9)), size=5, replace=True)\n",
    "# Calculate the mean of five_rolls\n",
    "mean_of_five_rolls = five_rolls.mean()\n",
    "print(mean_of_five_rolls)\n",
    "\n",
    "# Replicate the sampling code 1000 times\n",
    "sample_means_1000 = []\n",
    "for i in range(1000):\n",
    "    sample_means_1000.append(\n",
    "  \t\tnp.random.choice(list(range(1, 9)), size=5, replace=True).mean()\n",
    "    )\n",
    "\n",
    "# Draw a histogram of sample_means_1000 with 20 bins\n",
    "plt.hist(sample_means_1000,bins=20)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cental limit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate the the mean attritions for each sampling distribution\n",
    "sd_of_means_5 = np.mean(sampling_distribution_5)\n",
    "# Calculate the std. dev. of the mean attritions for each sampling distribution\n",
    "sd_of_means_5 = np.std(sampling_distribution_5,ddof=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Bootstrap Distributions\n",
    "Bootstrapping is, in some sense, the opposite of sampling from a population. Sampling treats your dataset as the population, and you generate a random subset. Bootstrapping treats your dataset as a sample and uses it to build up a theoretical population."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test auth"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
