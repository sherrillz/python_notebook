{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exploratory Data using Python"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Initial look"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import numpy as np\n",
    "# Load data\n",
    "unemployment = pd.read_csv('clean_unemployment.csv')\n",
    "books = pd.read_csv('clean_books.csv')\n",
    "salaries = pd.read_csv('sd_salaries_clean.csv')\n",
    "planes = pd.read_csv('planes.csv')\n",
    "# Initial look\n",
    "unemployment.head()\n",
    "unemployment.info()\n",
    "\n",
    "# A closer look at categorical columns\n",
    "unemployment.value_counts('catg_col')\n",
    "# numerical columns\n",
    "unemployment.describe()\n",
    "# hist plot for numerical columns\n",
    "sns.histplot(data=books,x=\"rating\",binwidth=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data type\n",
    "# can change the type to int/str/float/dict/list/bool\n",
    "df['column'] = df['column'].astype('int') \n",
    "\n",
    "# Validate categorical data\n",
    "df['catg_data'].isin(['first_data','second_data'])\n",
    "#* The data is not in\n",
    "~df['catg_data'].isin(['first_data','second_data'])\n",
    "\n",
    "# Validating Numeric Data\n",
    "df.select_types(\"number\")\n",
    "df['num_col'].min()\n",
    "df['num_col'].max()\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Missing Data\n",
    "### 1. Detect Missing Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Detecting Missing Value\n",
    "df.isna() # Return each columns and rows\n",
    "#Detecting any Missing value\n",
    "df.isna().any() # Return T/F of the summary of column\n",
    "# Counting missing value\n",
    "df.isna().sum()\n",
    "# Plotting missing values\n",
    "df.isna().sum().plot(kind = 'bar')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Dealing Missing Data\n",
    "\n",
    "- Drop missing values\n",
    "    5% or less of total values\n",
    "- Impute mean, median, mode\n",
    "    Depends on distribution and context\n",
    "- Impute by sub-group \n",
    "     Different experience levels have different median salary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Checking for missing values\n",
    "df.isna().sum()\n",
    "\n",
    "# If the NA is only a small amount and doesn't really matter\n",
    "df.dropna()\n",
    "# Replace with 0\n",
    "df.fillna(0)\n",
    "\n",
    "# Find the columns that have the missing value <=0.5 total value\n",
    "threshold = len(salaries) * 0.05\n",
    "cols_to_drop = df.columns[salaries.isna().sum() <= threshold]\n",
    "# Drop the NA in these columns\n",
    "salaries.dropna(subset=cols_to_drop, inplace=True)\n",
    "\n",
    "# Impute a summary statistics\n",
    "cols_with_missing_values = df.columns[df.isna().sum()> 0]\n",
    "for col in cols_with_missing_values[:-1]:\n",
    "    df[col].fillna(df[col].mode()[0])\n",
    "\n",
    "# Impute by sub-group\n",
    "salaries_dict = salaries.groupby(\"Experience\")[\"Salary_UsD\"].median().to_dict()\n",
    "# Output: {'Entry':!55380.0，'Executive':135439.0，'Mid':74173.5，'Senior':128903.0}\n",
    "salaries[\"Salary UsD\"] = salaries[\"Salary usp\"].fillna(salaries[\"Experience\"].map(salaries_dict))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Analyzing Categorical Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Preview Categorical data\n",
    "salaries.select_dtypes('object').head()\n",
    "# Count data under column\n",
    "salaries['Designation'].value_counts()\n",
    "# Check number of unique value\n",
    "salaries['Designation'].nunique()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Extracting value from categories"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Search a column for a specific string or multiple strings\n",
    "salaries[\"Designation\"].str.contains(\"Scientist\")\n",
    "# Finding multiple phrases in strings - using ``|``\n",
    "salaries[\"Designation\"].str.contains(\"Machine Learning|AI\")\n",
    "# Any that start with Data - using ``^``\n",
    "salaries[\"Designation\"].str.contains(\"^Data\")\n",
    "\n",
    "# Create a category column based on string conditions\n",
    "job_categories =[\"Data Science\",\"Data Analytics\",\"Data Engineering\",\n",
    "                  \"Machine Learning\"\"Consultant\",\"Managerial\"]\n",
    "\n",
    "# Create keywords for each job title\n",
    "data_science =\"Data Scientist|NLP\"\n",
    "data_analyst =\"Analyst|Analytics\"\n",
    "data_engineer = \"Data Engineer|ETL Architect|Infrastructure\"\n",
    "ml_engineer =\"Machine Learning|ML|Big Data|AI\"\n",
    "manager =\"Manager|Head|Director|Lead|Principal|Staff\"\n",
    "consultant=\"Consultant|Freelance\"\n",
    "\n",
    "# Create condition for each job title\n",
    "conditions = [\n",
    "    (salaries[\"Designation\"].str.contains(data_science)),\n",
    "    (salaries[\"Designation\"].str.contains(data_analyst)),\n",
    "    (salaries[\"Designation\"].str.contains(data_engineer)),\n",
    "    (salaries[\"Designation\"].str.contains(ml_engineer)),\n",
    "    (salaries[\"Designation\"].str.contains(manager))\n",
    "]\n",
    "\n",
    "# Create Category column\n",
    "salaries[\"Job_Category\"]=np.select(\n",
    "    conditions,\n",
    "    job_categories,\n",
    "    default=\"Other\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Analyzing Numeric Data\n",
    "Converting string to number "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Replace comma\n",
    "salaries['salary_in_rupees'] = salaries['salary_in_rupees'].srt.replace(\",\",\" \")\n",
    "# Convert string to number\n",
    "salaries['salary_in_rupees'] = salaries['salary_in_rupees'].astype(float)\n",
    "# Convert base on currency\n",
    "salaries['salary_in_USD'] = salaries['salary_in_rupees']*0.012\n",
    "# Summary statistics\n",
    "salaries.groupby('company_size')['salary_in_USD'].mean()\n",
    "# Add statistics in a DataFrame\n",
    "salaries[\"std_dev\"] = salaries.groupby(\"Experience\")[\"Salary_USD\"].transform(lambda x: x.std())\n",
    "#* transform: Operates on each group independently and applies the transformation to return a series that has the same index as the original DataFrame.\n",
    "#* lambda x: x.std():  computes the standard deviation of the Salary_USD values (x) for each group.\n",
    "#* x represents the subset of Salary_USD for each Experience group\n",
    "\n",
    "# Display the std on the group\n",
    "planes[[\"Airline\",\"airline_median_duration\"]].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Handling Outliers\n",
    "Why do these outliers exist?\n",
    "Is the data accurate?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Spot the outliers\n",
    "salaries['column1'].describe()\n",
    "\n",
    "# Identify thresholds\n",
    "#75th\n",
    "seventy_fifth =salaries[\"Salary_USD\"].quantile(0.75)\n",
    "#25th\n",
    "twenty_fifth =salaries[\"Salary_USD\"].quantile(0.25)\n",
    "# iqr\n",
    "salaries_iqr = seventy_fifth - twenty_fifth\n",
    "#  Upper  thresholds   \n",
    "upper = seventy_fifth + (1.5*salaries_iqr)\n",
    "#  Lower  thresholds\n",
    "lower =    twenty_fifth -  (1.5*salaries_iqr)\n",
    "#! Check if the thresholds is within a meaningful range\n",
    "\n",
    "# Subsetting the data, select the outliers\n",
    "salaries[(salaries[\"Salary_USD\"]<lower)|(salaries[\"Salary_UsD\"]> upper)][[\"Experience\",\"Employee_Location\",\"Salary_USD\"]]\n",
    "\n",
    "# Drop outliers\n",
    "no_outlier = salaries[(salaries[\"Salary_USD\"]>lower)&(salaries[\"Salary_UsD\"]< upper)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Relationship in Data\n",
    "### Dealing with time data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# change data type while read the file\n",
    "divorce = pd.read_csv(\"divorce.csv\", parse_dates=['marriage_date'])\n",
    "\n",
    "# Convert data to date\n",
    "divorce['marriage_date'] = pd.to_datetime(divorce['marriage_date'])\n",
    "\n",
    "# combine and convert to date type\n",
    "divorce['marriage_date'] = pd.to_datetime(divorce[['month','day','year']])\n",
    "\n",
    "# extract full date\n",
    "divorce['marriage_month'] = divorce['marriage_date'].dt.month"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Numeric Correlation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sea the corr of a dataset\n",
    "divorce.corr()\n",
    "# Visualize the corr in heatmap\n",
    "sns.heatmap(divorce.corr(),annot=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualizing Correlation\n",
    "sns.scatterplot(x=\"sleep_total\", y=\"sleep_rem\", data=msleep) \n",
    "# Adding a trendline\n",
    "sns.lmplot(x=\"sleep_total\", y=\"sleep_rem\", data=msleep, ci=None)\n",
    "# Computing correlation\n",
    "msleep['sleep_total'].corr(msleep['sleep_rem'])\n",
    "\n",
    "# Visualize in pairplot\n",
    "sns.pairplot(data = divorce)\n",
    "# Visualize only the concerned variables\n",
    "sns.pairplot(data = divorce, var = ['income_man','income_woman','marriage_duration'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Categorical Correlation\n",
    "**Kernel Density Estimate (KDE) plots:**\n",
    "creates a smooth curve that represents the data distribution, unlike histograms that use discrete bins"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# KDE\n",
    "sns.kdeplot(data=divorce, x=\"marriage_duration\", hue=\"education_man\")\n",
    "# Show data start from 0 in x-axis\n",
    "sns.kdeplot(data=divorce, x=\"marriage_duration\", hue=\"education_man\",cut = 0)\n",
    "# Cumulative KDE\n",
    "sns.kdeplot(data=divorce, x=\"marriage_duration\", hue=\"education_man\",cut = 0,cumulative=True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Class imbalance\n",
    "Class imbalance occurs in datasets where the number of observations for one class is significantly larger or smaller than the other classes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# class relative frequency \n",
    "salaries['Job_Category'].value_counts(normalize=True) # Normalization: standardizing the values as proportions\n",
    "# Cross-tabulation: Identify how observations occur in combination\n",
    "pd.crosstab(planes[\"Source\"],planes[\"Destination\"]) #'Source' is the index column and 'Destination' is the select column\n",
    "# Aggregated values with crosstab\n",
    "pd.crosstab(planes[\"Source\"],planes[\"Destination\"],values=planes[\"Price\"],aggfunc=\"median\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create new categorical columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define threshold\n",
    "twenty_fifth = planes[\"Price\"].quantile(0.25)\n",
    "median = planes[\"Price\"].median()\n",
    "seventy_fifth = planes[\"Price\"].quantile(0.75)\n",
    "maximum = planes[\"Price\"].max()\n",
    "# Set labels and bins\n",
    "labels =[\"Economy\",\"First Class\",\"Premium Economy\",\"Business Class\"] \n",
    "bins=[0,twenty_fifth, median,seventy_fifth, maximum]\n",
    "# Map number column to the category label\n",
    "planes[\"Price_Category\"]= pd.cut(planes[\"Price\"],Labels=labels,bins=bins)"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
